{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "912eca68-5220-4c97-827e-f6b2151247a4",
   "metadata": {},
   "source": [
    "# 03 DataSet Augmentation and Classification Model Training\n",
    "\n",
    "This code aims to augment the *Train Set* by making use of linguisitic patterns, train the cause-effect relation classification model (LSTM) and evaluate this Classification Model. \n",
    "\n",
    "* **Input**: The processed dataset including the sentences tagged with NPs Pairs.\n",
    "* **Approaches**: Define the labeling functions by using linguisitic patterns and use *Label Model* to get augmented *Train Set*; Apply LSTM to classify the sentences with cause-effect pairs.\n",
    "* **Output**: the cause-effect relation classification model based on LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f46d292-fec7-4ab9-b698-13c6cc452589",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import and install necessary packages\n",
    "\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import glob\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "path_here = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8223aa-34cd-411d-8230-99361a6853e7",
   "metadata": {},
   "source": [
    "## 03-A. Partition datasets\n",
    "train set: 70%; dev set: 20%; test set: 10%;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3d72740-9abe-4674-9f81-83aedd6f117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### purpose: to get the binary labels of one pair  (1: postive pairs; -1: negative pairs)\n",
    "### input: (dataframe containg each sentence, all seed pairs)\n",
    "### output: the binary labels of one pair\n",
    "def get_BiLabel(df_enwiki_causality, causal_pairs):\n",
    "    \n",
    "    tuple_pairs = [[i,j] for i, j, k in causal_pairs] # the first two \n",
    "    label_ls = []\n",
    "\n",
    "    for index, row in df_enwiki_causality.iterrows():\n",
    "        if row['pairs'] in tuple_pairs:\n",
    "            ind = tuple_pairs.index(row['pairs'])\n",
    "            label_ls.append(1)\n",
    "        else:\n",
    "            label_ls.append(-1)\n",
    "    \n",
    "    print(Counter(label_ls))\n",
    "    return label_ls\n",
    "\n",
    "### purpose: partition the dataset into train, deve and test\n",
    "### input: one dataframe containing each sentence\n",
    "### output: 3 datamfranes containing each sentence\n",
    "def partition(df_enwiki_causality_v4):\n",
    "    nb_train = 6\n",
    "    nb_dev = 2\n",
    "    nb_test = 2\n",
    "    \n",
    "    index_shuffle = [i for i in df_enwiki_causality_v4.index]\n",
    "    random.shuffle(index_shuffle)\n",
    "    list_shuffle = [index_shuffle[i::10] for i in range(10)]\n",
    "    \n",
    "    df_train = df_enwiki_causality_v4.iloc[[j for i in list_shuffle[:nb_train] for j in i]]\n",
    "    df_dev = df_enwiki_causality_v4.iloc[[j for i in list_shuffle[nb_train:nb_train+nb_dev] for j in i]]\n",
    "    df_test = df_enwiki_causality_v4.iloc[[j for i in list_shuffle[nb_train+nb_dev:10] for j in i]]\n",
    "    \n",
    "    return df_train, df_dev, df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "517c9001-2ffa-4bd9-819b-65ec89944ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# partition dataset\n",
    "df_enwiki_causality_v4 = pd.read_pickle(path_here + '/res/df_enwiki_causality.pkl')\n",
    "df_train, df_dev, df_test = partition(df_enwiki_causality_v4)\n",
    "# len(df_train) + len(df_dev) + len(df_test) == len(df_enwiki_causality_v4)  # test: correct\n",
    "\n",
    "# get the binary labels for those pairs (whether they are causal pairs)\n",
    "df_causalpairs_train = pd.read_csv(path_here + '/res/df_causalpairs_train2.csv', index_col = 0)\n",
    "causal_pairs = [df_causalpairs_train.loc[i].to_list()[1:4] for i in range(len(df_causalpairs_train))] \n",
    "Y_dev = get_BiLabel(df_dev, causal_pairs)\n",
    "\n",
    "df_causalpairs_test = pd.read_csv(path_here + '/res/df_causalpairs_test2.csv', index_col = 0)\n",
    "causal_pairs_test = [df_causalpairs_test.loc[i].to_list()[1:4] for i in range(len(df_causalpairs_test))] \n",
    "Y_test = get_BiLabel(df_test, causal_pairs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a39d252-a868-4bf3-bcfa-4598faeace7b",
   "metadata": {},
   "source": [
    "## 03-B. Define the labeing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a455d0f1-0061-48aa-9ee5-c924f70a0119",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from preprocessors_03 import get_NPs_text, get_text_between, get_left_tokens, get_right_tokens\n",
    "\n",
    "POSITIVE = 1\n",
    "NEGATIVE = 0\n",
    "ABSTAIN = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd32de15-a511-454c-814c-ca601d7662f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define the labeling functions\n",
    "\n",
    "\n",
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "\n",
    "# Check for the `causal connectives` words appearing between the mentions\n",
    "causalConnectives = {'for this reason', 'with the result that', 'because of','thanks to', 'due to',\n",
    "                    'beause', 'as', 'since', 'so', 'so that',\n",
    "                    'the reason was that', 'is due to'}\n",
    "@labeling_function(resources=dict(causalConnectives=causalConnectives), pre=[get_text_between])\n",
    "def lf_causalConnectives(x, causalConnectives):\n",
    "    if len(causalConnectives.intersection(set(x.text_between))) > 0 :\n",
    "        return POSITIVE   \n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# Check for the `causation verbs` words appearing between the mentions\n",
    "causationVerbs = {'cause', 'lead to', 'bring about', 'generate', 'make', 'force', 'allow',\n",
    "                 'kill', 'melt', 'dry', 'break', 'drop', \n",
    "                 'poison', 'hang', 'punch', 'clean',\n",
    "                 'blacken', 'sweeten', 'thicken', 'nullify', 'liquefy', 'verify',\n",
    "                 'kill', 'feed', 'die', 'eat'}\n",
    "@labeling_function(resources=dict(causationVerbs=causationVerbs), pre=[get_text_between])\n",
    "def lf_causationVerbs(x, causationVerbs):\n",
    "    return POSITIVE if len(causationVerbs.intersection(set(x.text_between))) > 0 else ABSTAIN\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Check for the `causation adverbs` words appearing to the left and right of the mentions\n",
    "causationAdverbs = {'audibly', 'visibly',\n",
    "                   'manilestly', 'publicly', 'conspicuously',\n",
    "                   'successfully', 'plausibly', 'conveniently', 'amusingly', 'pleasantly',\n",
    "                   'irrevocably', 'ously', 'rudely',\n",
    "                   'obediently', 'gratefully', 'consequently', 'painfully',\n",
    "                   'mechanically', 'magically'}\n",
    "\n",
    "@labeling_function(resources=dict(causationAdverbs=causationAdverbs), pre=[get_left_tokens])\n",
    "def lf_causationAdverbs_left(x, causationAdverbs):\n",
    "    if len(set(causationAdverbs).intersection(set(x.ele1_left_tokens))) > 0:\n",
    "        return POSITIVE\n",
    "    elif len(set(causationAdverbs).intersection(set(x.ele2_left_tokens))) > 0:\n",
    "        return POSITIVE\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "@labeling_function(resources=dict(causationAdverbs=causationAdverbs), pre=[get_right_tokens])\n",
    "def lf_causationAdverbs_right(x, causationAdverbs):\n",
    "    if len(set(causationAdverbs).intersection(set(x.ele1_right_tokens))) > 0:\n",
    "        return POSITIVE\n",
    "    elif len(set(causationAdverbs).intersection(set(x.ele2_right_tokens))) > 0:\n",
    "        return POSITIVE\n",
    "    else:\n",
    "        return ABSTAIN    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24d8c615-158c-4c2a-a6c3-f49b37c5c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define the Distant Supervision labeling function \n",
    "\n",
    "# the methods to download the knowledges from Wiki Data --> apply \"has cause (P828)\" to the query in this link <https://query.wikidata.org/#PREFIX%20wd%3A%20%3Chttp%3A%2F%2Fwww.wikidata.org%2Fentity%2F%3E%0APREFIX%20wdt%3A%20%3Chttp%3A%2F%2Fwww.wikidata.org%2Fprop%2Fdirect%2F%3E%0APREFIX%20rdfs%3A%20%3Chttp%3A%2F%2Fwww.w3.org%2F2000%2F01%2Frdf-schema%23%3E%0APREFIX%20p%3A%20%3Chttp%3A%2F%2Fwww.wikidata.org%2Fprop%2F%3E%0APREFIX%20v%3A%20%3Chttp%3A%2F%2Fwww.wikidata.org%2Fprop%2Fstatement%2F%3E%0A%0ASELECT%20%3Fx%20%3Fx_label%20%3Fy%20%3Fy_label%20WHERE%20%7B%0A%09%3Fx%20wdt%3AP828%20%3Fy%20.%0A%09OPTIONAL%20%7B%0A%09%09%3Fx%20rdfs%3Alabel%20%3Fx_label%20FILTER%20%28lang%28%3Fx_label%29%20%3D%20%22en%22%29%20.%0A%20%20%20%20%20%20%20%20%3Fy%20rdfs%3Alabel%20%3Fy_label%20FILTER%20%28lang%28%3Fy_label%29%20%3D%20%22en%22%29%20.%0A%09%7D%0A%7D> \n",
    "known_Causality = pd.read_csv(path_here +'/data/query.tsv', sep='\\t')\n",
    "\n",
    "# delete the labels' rows including NaN;\n",
    "known_Causality = known_Causality.dropna()\n",
    "known_CauseEffect_pairs = list(zip(known_Causality['x_label'].str.lower(), known_Causality['y_label'].str.lower()))\n",
    "\n",
    "@labeling_function(resources=dict(known_CauseEffect_pairs=known_CauseEffect_pairs), pre=[get_NPs_text])\n",
    "def lf_distant_supervision(x, known_CauseEffect_pairs):\n",
    "    p1, p2 = x.NPs\n",
    "    if (p1, p2) in known_CauseEffect_pairs:\n",
    "        return POSITIVE\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "923caf8a-c41b-42e9-9afc-bcc5cd8efa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Apply Labeling Functions to the Data\n",
    "\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "lfs = [\n",
    "    lf_causalConnectives,\n",
    "    lf_causationVerbs, \n",
    "    lf_causationAdverbs_left,\n",
    "    lf_causationAdverbs_right,\n",
    "    lf_distant_supervision\n",
    "    ]\n",
    "applier = PandasLFApplier(lfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ca143de-44d5-4782-95ea-1d0cd516026d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82060/82060 [03:16<00:00, 417.17it/s]\n",
      "100%|██████████| 246184/246184 [09:49<00:00, 417.71it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "L_dev = applier.apply(df_dev)\n",
    "L_train = applier.apply(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ecc56308-8cd5-4af7-920b-3af30526c569",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/snorkel/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[-1  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n",
      "/anaconda3/envs/snorkel/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[-1  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n",
      "/anaconda3/envs/snorkel/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[-1  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n",
      "/anaconda3/envs/snorkel/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[-1  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n",
      "/anaconda3/envs/snorkel/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[-1  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lf_causalConnectives</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.098672</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_causationVerbs</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.011687</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_causationAdverbs_left</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_causationAdverbs_right</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_distant_supervision</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "lf_causalConnectives       0  [1]      0.098672  0.002084  0.0        33        \n",
       "lf_causationVerbs          1  [1]      0.011687  0.001999  0.0        9         \n",
       "lf_causationAdverbs_left   2  [1]      0.000256  0.000037  0.0        0         \n",
       "lf_causationAdverbs_right  3  [1]      0.000390  0.000073  0.0        0         \n",
       "lf_distant_supervision     4  [1]      0.000427  0.000024  0.0        0         \n",
       "\n",
       "                           Incorrect  Emp. Acc.  \n",
       "lf_causalConnectives       0          0.004076   \n",
       "lf_causationVerbs          0          0.009385   \n",
       "lf_causationAdverbs_left   0          0.000000   \n",
       "lf_causationAdverbs_right  0          0.000000   \n",
       "lf_distant_supervision     0          0.000000   "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_analysis = LFAnalysis(L_dev, lfs).lf_summary(np.array(Y_dev))\n",
    "dev_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c7eee6-847b-4c0a-b373-05732eb5432a",
   "metadata": {},
   "source": [
    "## 03-C. Train labeling model for augmentated Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "40109b59-e1c4-4712-8848-5c41b57a3370",
   "metadata": {},
   "outputs": [],
   "source": [
    "### training labeling model (try to converge several LFs into the single models)\n",
    "\n",
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train, np.array(Y_dev), n_epochs=5000, log_freq=500, seed=12345)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9f60efbb-eebb-4132-948a-3fd30ca50359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label model accuracy score: 0.9936997319034853\n",
      "Label model precision score: 0.0\n",
      "Label model recall score: 0.0\n",
      "Label model f1 score: 0.0\n",
      "Label model roc-auc: 0.5248609225508569\n"
     ]
    }
   ],
   "source": [
    "### Evaluate the label model\n",
    "\n",
    "from snorkel.analysis import metric_score\n",
    "from snorkel.utils import probs_to_preds\n",
    "\n",
    "probs_dev = label_model.predict_proba(L_dev)\n",
    "preds_dev = probs_to_preds(probs_dev)\n",
    "# change the results only containing <0 and 1>\n",
    "Y_dev_01 = np.array([x if x==1 else 0 for x in Y_dev])\n",
    "\n",
    "\n",
    "print(f\"Label model accuracy score: {metric_score(Y_dev_01, preds_dev, probs=probs_dev, metric='accuracy')}\")\n",
    "print(f\"Label model precision score: {metric_score(Y_dev_01, preds_dev, probs=probs_dev, metric='precision')}\")\n",
    "print(f\"Label model recall score: {metric_score(Y_dev_01, preds_dev, probs=probs_dev, metric='recall')}\")\n",
    "print(f\"Label model f1 score: {metric_score(Y_dev_01, preds_dev, probs=probs_dev, metric='f1')}\")\n",
    "print(f\"Label model roc-auc: {metric_score(Y_dev_01, preds_dev, probs=probs_dev, metric='roc_auc')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d1094b0-1f26-4bd5-8e66-ba5defb2e347",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter out training data points which did not recieve a label from any LF\n",
    "\n",
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "probs_train = label_model.predict_proba(L_train)\n",
    "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=df_train, y=probs_train, L=L_train)\n",
    "\n",
    "# convert the label into unite\n",
    "Y_train_filter = [0 if i[0] > i[1] else 1 for i in probs_train_filtered]        \n",
    "Y_train_filter_tf= [False if i==0 else True for i in Y_train_filter] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d2dd1a-9526-441c-bbff-a49f2f7b6a8b",
   "metadata": {},
   "source": [
    "## 03-D. Train cause-effect relation classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "16ae2b2c-77da-4c86-8431-de6beacf3a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### purpose: to add dataframe with more columns for the usage of LSTM\n",
    "### input: one dataframe containing each sentence\n",
    "### output: one datamfrane has 3 columns more\n",
    "def add3colDf(df_train_filtered):\n",
    "    \n",
    "    # be aware it will be the new dataframe\n",
    "    new_list = df_train_filtered.columns.to_list()\n",
    "    t_list = ['text_between', 'ele1_left_tokens', 'ele2_right_tokens']\n",
    "    new_list.extend(t_list)\n",
    "    df = pd.DataFrame(columns = new_list)\n",
    "\n",
    "    for ind, rows in df_train_filtered.iterrows():\n",
    "        text_between = rows['tokens'][rows['ele1_word_idx'][1]+1: rows['ele2_word_idx'][0]]\n",
    "        ele1_left_tokens = rows['tokens'][:rows['ele1_word_idx'][0]]\n",
    "        ele2_right_tokens = rows['tokens'][rows['ele2_word_idx'][1]+1:]\n",
    "\n",
    "        ### add the new row\n",
    "        dict_newrow = dict(rows)\n",
    "        dict_newrow.update({ 'ele1_left_tokens': ele1_left_tokens, \n",
    "                  'text_between': text_between, 'ele2_right_tokens': ele2_right_tokens})\n",
    "\n",
    "        ### new dataframe\n",
    "        df = df.append(dict_newrow, ignore_index = True)\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d707cb3f-0cd5-490c-ac17-044dd60056aa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/snorkel/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /anaconda3/envs/snorkel/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /anaconda3/envs/snorkel/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /anaconda3/envs/snorkel/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /anaconda3/envs/snorkel/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /anaconda3/envs/snorkel/lib/python3.6/site-packages/tensorflow/python/keras/backend.py:3794: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/zoe/Desktop/codes/GSOC_RelationExtraction/tf_model_03.py:68: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/envs/snorkel/lib/python3.6/site-packages/tensorflow/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "27073/27073 [==============================] - 63s 2ms/sample - loss: 0.2585\n",
      "Epoch 2/30\n",
      "27073/27073 [==============================] - 57s 2ms/sample - loss: 0.2539\n",
      "Epoch 3/30\n",
      "27073/27073 [==============================] - 56s 2ms/sample - loss: 0.2517\n",
      "Epoch 4/30\n",
      "27073/27073 [==============================] - 57s 2ms/sample - loss: 0.2480\n",
      "Epoch 5/30\n",
      "27073/27073 [==============================] - 56s 2ms/sample - loss: 0.2312\n",
      "Epoch 6/30\n",
      "27073/27073 [==============================] - 57s 2ms/sample - loss: 0.2258\n",
      "Epoch 7/30\n",
      "27073/27073 [==============================] - 57s 2ms/sample - loss: 0.2225\n",
      "Epoch 8/30\n",
      "27073/27073 [==============================] - 57s 2ms/sample - loss: 0.2193\n",
      "Epoch 9/30\n",
      "27073/27073 [==============================] - 57s 2ms/sample - loss: 0.2146\n",
      "Epoch 10/30\n",
      "27073/27073 [==============================] - 57s 2ms/sample - loss: 0.2078\n",
      "Epoch 11/30\n",
      "27073/27073 [==============================] - 57s 2ms/sample - loss: 0.2033\n",
      "Epoch 12/30\n",
      "27073/27073 [==============================] - 57s 2ms/sample - loss: 0.1988\n",
      "Epoch 13/30\n",
      "27073/27073 [==============================] - 57s 2ms/sample - loss: 0.1961\n",
      "Epoch 14/30\n",
      "27073/27073 [==============================] - 57s 2ms/sample - loss: 0.1942\n",
      "Epoch 15/30\n",
      "27073/27073 [==============================] - 57s 2ms/sample - loss: 0.1917\n",
      "Epoch 16/30\n",
      "27073/27073 [==============================] - 57s 2ms/sample - loss: 0.1911\n",
      "Epoch 17/30\n",
      "27073/27073 [==============================] - 59s 2ms/sample - loss: 0.1923\n",
      "Epoch 18/30\n",
      "27073/27073 [==============================] - 57s 2ms/sample - loss: 0.1904\n",
      "Epoch 19/30\n",
      "27073/27073 [==============================] - 57s 2ms/sample - loss: 0.1901\n",
      "Epoch 20/30\n",
      "27073/27073 [==============================] - 56s 2ms/sample - loss: 0.1897\n",
      "Epoch 21/30\n",
      "27073/27073 [==============================] - 57s 2ms/sample - loss: 0.1895\n",
      "Epoch 22/30\n",
      "27073/27073 [==============================] - 55s 2ms/sample - loss: 0.1894\n",
      "Epoch 23/30\n",
      "27073/27073 [==============================] - 53s 2ms/sample - loss: 0.1893\n",
      "Epoch 24/30\n",
      "27073/27073 [==============================] - 59s 2ms/sample - loss: 0.1893\n",
      "Epoch 25/30\n",
      "27073/27073 [==============================] - 59s 2ms/sample - loss: 0.1892\n",
      "Epoch 26/30\n",
      "27073/27073 [==============================] - 59s 2ms/sample - loss: 0.1891\n",
      "Epoch 27/30\n",
      "27073/27073 [==============================] - 60s 2ms/sample - loss: 0.1890\n",
      "Epoch 28/30\n",
      "27073/27073 [==============================] - 61s 2ms/sample - loss: 0.1891\n",
      "Epoch 29/30\n",
      "27073/27073 [==============================] - 68s 3ms/sample - loss: 0.1890\n",
      "Epoch 30/30\n",
      "27073/27073 [==============================] - 60s 2ms/sample - loss: 0.1889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d6595748>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Training our End Extraction Model (LSTM)\n",
    "\n",
    "from tf_model_03 import get_model, get_feature_arrays\n",
    "from utils_03 import get_n_epochs\n",
    "\n",
    "# prepare the train dataframe with more columns\n",
    "df_train_filtered_3more = add3colDf(df_train_filtered)\n",
    "\n",
    "X_train = get_feature_arrays(df_train_filtered_3more)\n",
    "model = get_model()\n",
    "batch_size = 64\n",
    "model.fit(X_train, probs_train_filtered, batch_size=batch_size, epochs=get_n_epochs())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eceb9c87-d90d-45c4-b9fa-a881e053cd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 when trained with soft labels: 0.0004102717117654738\n",
      "Test ROC-AUC when trained with soft labels: 0.5283391564394855\n"
     ]
    }
   ],
   "source": [
    "### Evaluating the trained model on the test set(LSTM)\n",
    "\n",
    "# prepare the test dataframe with more columns\n",
    "df_test_3more = add3colDf(df_test)\n",
    "\n",
    "X_test = get_feature_arrays(df_test_3more)\n",
    "probs_test = model.predict(X_test)\n",
    "preds_test = probs_to_preds(probs_test)\n",
    "\n",
    "# change the results only containing <0 and 1>\n",
    "Y_test_01 = np.array([x if x==1 else 0 for x in Y_test])\n",
    "\n",
    "print(f\"Test accuracy when trained with soft labels: {metric_score(Y_test_01, preds_dev, probs=probs_dev, metric='accuracy')}\")\n",
    "print(f\"Test precision when trained with soft labels: {metric_score(Y_test_01, preds_dev, probs=probs_dev, metric='precision')}\")\n",
    "print(f\"Test recall when trained with soft labels: {metric_score(Y_test_01, preds_dev, probs=probs_dev, metric='recall')}\")\n",
    "print(f\"Test F1 when trained with soft labels: {metric_score(Y_test_01, preds_dev, probs=probs_dev, metric='f1')}\")\n",
    "print(f\"Test ROC-AUC when trained with soft labels: {metric_score(Y_test_01, preds_dev, probs=probs_dev, metric='roc_auc')}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8b307c19-924b-4b96-81dd-a6db633be983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy when trained with soft labels: 0.9967462832074092\n",
      "Test precision when trained with soft labels: 0.0\n",
      "Test recall when trained with soft labels: 0.0\n",
      "Test F1 when trained with soft labels: 0.0\n",
      "Test ROC-AUC when trained with soft labels: 0.5355835641424763\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
