{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8d5748d-4e0d-4f8d-8029-865f4c85b3b4",
   "metadata": {},
   "source": [
    "# 03 Classification Models\n",
    "\n",
    "This code aims to train classification models to recognize the causality sentences from wikipages\n",
    "\n",
    "* **Input**: The semEval dataframes\n",
    "* **Approaches**: get the sentence embeddings to train on the *Logistic Regression* classifier; apply the *LSTM classifier* with specific sentence embedding techniques\n",
    "* **Output**: Evaluate the models with different metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68ba3b12-8415-428d-91a1-51bbc53b0426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/snorkel/lib/python3.6/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spacy_entity_linker\n"
     ]
    }
   ],
   "source": [
    "### import and install necessary packages\n",
    "\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import glob\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle \n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument  # sentece to vec\n",
    "\n",
    "from sklearn import metrics # for evaluation\n",
    "from sklearn.linear_model import LogisticRegression # classifer\n",
    "\n",
    "import spacy\n",
    "nlp= spacy.load('en_core_web_sm') # tokenized sentence\n",
    "\n",
    "path_here = os.getcwd()\n",
    "\n",
    "# to install if you don't install yet\n",
    "# !{sys.executable} -m pip install tensorflow\n",
    "from tf_model_03 import get_model, get_feature_arrays\n",
    "from utils_03 import get_n_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52c2173f-4889-456f-9061-75a005301694",
   "metadata": {},
   "outputs": [],
   "source": [
    "### the initialized parameters\n",
    "\n",
    "df_res_dev = pd.DataFrame(columns = ['tag', 'Nb:allsamp,predpos,realpos,overlap', 'accuracy', 'precision',\n",
    "                                    'recall', 'F1'])\n",
    "### get the sentences of semEval\n",
    "df_train_semEval = pd.read_pickle(path_here+ \"/res/df_train_semEval.pkl\")\n",
    "df_test_semEval = pd.read_pickle(path_here+ \"/res/df_test_semEval.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3bad169-6de9-49d9-baf0-1cc56f544c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "### purpose: get the embedding of the subset sentences \n",
    "### input: df_subset, the trained whole model\n",
    "### output: the embedding feature space\n",
    "def GetEmb(df_subset, model):\n",
    "\n",
    "    wv_doc2vec = []\n",
    "    for inx in df_subset.index.tolist():\n",
    "        wv_doc2vec.append(model.dv[inx])\n",
    "    return np.array(wv_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c970aeb2-e671-4bde-af25-3268f83072f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished Round 0\n",
      "finished Round 1\n",
      "finished Round 2\n",
      "finished Round 3\n",
      "finished Round 4\n"
     ]
    }
   ],
   "source": [
    "### train the Logistic Regression Classifier\n",
    "\n",
    "\n",
    "# the inputting dataframes\n",
    "df_train_semEval.index = range(len(df_train_semEval))\n",
    "df_test_semEval.index = range(len(df_train_semEval),len(df_train_semEval)+len(df_test_semEval))\n",
    "Y_train_semEval = df_train_semEval['Label'].tolist()\n",
    "Y_test_semEval = df_test_semEval['Label'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "for rd in range(5):\n",
    "\n",
    "    NameTag = 'LR_Round{}'.format(rd)\n",
    "\n",
    "    ### try to embedding the sentences by doc2ve\n",
    "    doc_list = df_train_semEval['Sent'].tolist()\n",
    "    doc_list.extend(df_test_semEval['Sent'].tolist())\n",
    "    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(doc_list)]\n",
    "    model_doc2vec = Doc2Vec(documents, vector_size=50, window=5, min_count=2, workers=4)\n",
    "\n",
    "    ### get the sentence embedding \n",
    "    wv_semEval_train = GetEmb(df_train_semEval, model_doc2vec)\n",
    "    ### get the sentence embedding of test set\n",
    "    wv_semEval_test = GetEmb(df_test_semEval, model_doc2vec)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### train the LogisticRegression classifer and evaluate\n",
    "    X = wv_semEval_train\n",
    "    y = Y_train_semEval\n",
    "    clf_lr = LogisticRegression(random_state=0).fit(X, y)\n",
    "    ### test this classifer\n",
    "    X_test = wv_semEval_test\n",
    "    preds_test = clf_lr.predict(X_test)\n",
    "    probs_test = clf_lr.predict_proba(X_test)\n",
    "    df_res_dev = df_res_dev.append({'tag': NameTag,\n",
    "                                    # all samples; predicted postive , real postive, overlap postive\n",
    "                                    'Nb:allsamp,predpos,realpos,overlap': [len(preds_test), Counter(preds_test)[1], Counter(Y_test_semEval)[1], \n",
    "                                    len([i for inx, i in enumerate(preds_test) if i == Y_test_semEval[inx]])],\n",
    "                                    # metrics values\n",
    "                                    'accuracy': metrics.accuracy_score(Y_test_semEval, preds_test), \n",
    "                                    'precision': metrics.precision_score(Y_test_semEval, preds_test),\n",
    "                                    'recall': metrics.recall_score(Y_test_semEval, preds_test),\n",
    "                                    'F1': metrics.f1_score(Y_test_semEval, preds_test),\n",
    "                                   }, ignore_index=True)\n",
    "     \n",
    "    print(\"finished Round {}\".format(rd))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e63ab5c-7b85-4cdb-a12f-45a31eafb1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>Nb:allsamp,predpos,realpos,overlap</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR_Round0</td>\n",
       "      <td>[656, 260, 328, 338]</td>\n",
       "      <td>0.515244</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.411585</td>\n",
       "      <td>0.459184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR_Round1</td>\n",
       "      <td>[656, 243, 328, 363]</td>\n",
       "      <td>0.553354</td>\n",
       "      <td>0.572016</td>\n",
       "      <td>0.423780</td>\n",
       "      <td>0.486865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR_Round2</td>\n",
       "      <td>[656, 264, 328, 362]</td>\n",
       "      <td>0.551829</td>\n",
       "      <td>0.564394</td>\n",
       "      <td>0.454268</td>\n",
       "      <td>0.503378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR_Round3</td>\n",
       "      <td>[656, 261, 328, 357]</td>\n",
       "      <td>0.544207</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.442073</td>\n",
       "      <td>0.492360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR_Round0</td>\n",
       "      <td>[656, 266, 328, 358]</td>\n",
       "      <td>0.545732</td>\n",
       "      <td>0.556391</td>\n",
       "      <td>0.451220</td>\n",
       "      <td>0.498316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR_Round0</td>\n",
       "      <td>[656, 247, 328, 359]</td>\n",
       "      <td>0.547256</td>\n",
       "      <td>0.562753</td>\n",
       "      <td>0.423780</td>\n",
       "      <td>0.483478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR_Round1</td>\n",
       "      <td>[656, 244, 328, 344]</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.532787</td>\n",
       "      <td>0.396341</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR_Round2</td>\n",
       "      <td>[656, 252, 328, 340]</td>\n",
       "      <td>0.518293</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.402439</td>\n",
       "      <td>0.455172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LR_Round3</td>\n",
       "      <td>[656, 257, 328, 363]</td>\n",
       "      <td>0.553354</td>\n",
       "      <td>0.568093</td>\n",
       "      <td>0.445122</td>\n",
       "      <td>0.499145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LR_Round4</td>\n",
       "      <td>[656, 271, 328, 353]</td>\n",
       "      <td>0.538110</td>\n",
       "      <td>0.546125</td>\n",
       "      <td>0.451220</td>\n",
       "      <td>0.494157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tag Nb:allsamp,predpos,realpos,overlap  accuracy  precision  \\\n",
       "0  LR_Round0               [656, 260, 328, 338]  0.515244   0.519231   \n",
       "1  LR_Round1               [656, 243, 328, 363]  0.553354   0.572016   \n",
       "2  LR_Round2               [656, 264, 328, 362]  0.551829   0.564394   \n",
       "3  LR_Round3               [656, 261, 328, 357]  0.544207   0.555556   \n",
       "4  LR_Round0               [656, 266, 328, 358]  0.545732   0.556391   \n",
       "5  LR_Round0               [656, 247, 328, 359]  0.547256   0.562753   \n",
       "6  LR_Round1               [656, 244, 328, 344]  0.524390   0.532787   \n",
       "7  LR_Round2               [656, 252, 328, 340]  0.518293   0.523810   \n",
       "8  LR_Round3               [656, 257, 328, 363]  0.553354   0.568093   \n",
       "9  LR_Round4               [656, 271, 328, 353]  0.538110   0.546125   \n",
       "\n",
       "     recall        F1  \n",
       "0  0.411585  0.459184  \n",
       "1  0.423780  0.486865  \n",
       "2  0.454268  0.503378  \n",
       "3  0.442073  0.492360  \n",
       "4  0.451220  0.498316  \n",
       "5  0.423780  0.483478  \n",
       "6  0.396341  0.454545  \n",
       "7  0.402439  0.455172  \n",
       "8  0.445122  0.499145  \n",
       "9  0.451220  0.494157  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3318fe4c-a81a-4bf5-9fcb-5adeeabe6061",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### purpose: to find the index of NPs pairs in sentences\n",
    "### input: The SemEval Dataframe\n",
    "### output: The SemEval Dataframe with 3 more columns <'ele1_word_idx', 'ele2_word_idx', 'tokens'>\n",
    "\n",
    "def addInxcolDf(df_train_filtered):\n",
    "    # be aware it will be the new dataframe\n",
    "    new_list = df_train_filtered.columns.to_list()\n",
    "    t_list = ['ele1_word_idx', 'ele2_word_idx', 'tokens']\n",
    "    new_list.extend(t_list)\n",
    "    df = pd.DataFrame(columns = new_list)\n",
    "    \n",
    "    # find index of all tokens in one NP \n",
    "    def findInx(tokens):\n",
    "        ls = ['Cause', 'Effect']\n",
    "        res = []\n",
    "        for v in ls: \n",
    "            ele_A = re.findall(r\"[\\w']+|[.,!?;-]\", rows[v])\n",
    "            try: \n",
    "                inx_l = tokens.index(ele_A[0])\n",
    "                inx_r = tokens.index(ele_A[-1])\n",
    "                tu_A = (inx_l, inx_r)\n",
    "            except:\n",
    "                tu_A = (0, 0)\n",
    "            res.append(tu_A)\n",
    "        return res[0], res[1]\n",
    "    \n",
    "\n",
    "    for ind, rows in df_train_filtered.iterrows():\n",
    "        doc = nlp(rows['Sent'])\n",
    "        tokens = [token.text.lower() for token in doc]\n",
    "\n",
    "        tu_A, tu_B = findInx(tokens)\n",
    "        # ensure left index is the smallest\n",
    "        if tu_A[0] > tu_B[0]:\n",
    "            ele1_word_idx = tu_B\n",
    "            ele2_word_idx = tu_A            \n",
    "        else:\n",
    "            ele1_word_idx = tu_A\n",
    "            ele2_word_idx = tu_B\n",
    "\n",
    "        ### add the new row\n",
    "        dict_newrow = dict(rows)\n",
    "        dict_newrow.update({ 'ele1_word_idx': ele1_word_idx, \n",
    "                  'ele2_word_idx': ele2_word_idx, 'tokens': tokens})\n",
    "\n",
    "        ### new dataframe\n",
    "        df = df.append(dict_newrow, ignore_index = True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "### purpose: add 3 more columns of SemEval Dataframe to prepare the inputting data for LSTM\n",
    "### input: The SemEval Dataframe with 3 more columns <'ele1_word_idx', 'ele2_word_idx', 'tokens'>\n",
    "### output: The SemEval Dataframe with extra columns <'text_between', 'ele1_left_tokens', 'ele2_right_tokens'>\n",
    "\n",
    "def add3colDf(df_train_filtered):\n",
    "    # be aware it will be the new dataframe\n",
    "    new_list = df_train_filtered.columns.to_list()\n",
    "    t_list = ['text_between', 'ele1_left_tokens', 'ele2_right_tokens']\n",
    "    new_list.extend(t_list)\n",
    "    df = pd.DataFrame(columns = new_list)\n",
    "\n",
    "    for ind, rows in df_train_filtered.iterrows():\n",
    "        text_between = rows['tokens'][rows['ele1_word_idx'][1]+1: rows['ele2_word_idx'][0]]\n",
    "        ele1_left_tokens = rows['tokens'][:rows['ele1_word_idx'][0]]\n",
    "        ele2_right_tokens = rows['tokens'][rows['ele2_word_idx'][1]+1:]\n",
    "\n",
    "        ### add the new row\n",
    "        dict_newrow = dict(rows)\n",
    "        dict_newrow.update({ 'ele1_left_tokens': ele1_left_tokens, \n",
    "                  'text_between': text_between, 'ele2_right_tokens': ele2_right_tokens})\n",
    "\n",
    "        ### new dataframe\n",
    "        df = df.append(dict_newrow, ignore_index = True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d073fcfb-04f4-439d-a7d3-6dfcf6592af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/snorkel/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /anaconda3/envs/snorkel/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /anaconda3/envs/snorkel/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /anaconda3/envs/snorkel/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /anaconda3/envs/snorkel/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /anaconda3/envs/snorkel/lib/python3.6/site-packages/tensorflow/python/keras/backend.py:3794: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/zoe/Desktop/codes/GSOC_RelationExtraction_github/tf_model_03.py:69: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/envs/snorkel/lib/python3.6/site-packages/tensorflow/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Epoch 1/30\n",
      "2006/2006 [==============================] - 9s 4ms/sample - loss: 0.6938\n",
      "Epoch 2/30\n",
      "2006/2006 [==============================] - 4s 2ms/sample - loss: 0.6938\n",
      "Epoch 3/30\n",
      "2006/2006 [==============================] - 4s 2ms/sample - loss: 0.6935\n",
      "Epoch 4/30\n",
      "2006/2006 [==============================] - 4s 2ms/sample - loss: 0.6934\n",
      "Epoch 5/30\n",
      "2006/2006 [==============================] - 4s 2ms/sample - loss: 0.6932\n",
      "Epoch 6/30\n",
      "2006/2006 [==============================] - 4s 2ms/sample - loss: 0.6923\n",
      "Epoch 7/30\n",
      "2006/2006 [==============================] - 5s 2ms/sample - loss: 0.6910\n",
      "Epoch 8/30\n",
      "2006/2006 [==============================] - 4s 2ms/sample - loss: 0.6901\n",
      "Epoch 9/30\n",
      "2006/2006 [==============================] - 4s 2ms/sample - loss: 0.6866\n",
      "Epoch 10/30\n",
      "2006/2006 [==============================] - 5s 2ms/sample - loss: 0.6766\n",
      "Epoch 11/30\n",
      "2006/2006 [==============================] - 5s 2ms/sample - loss: 0.6431\n",
      "Epoch 12/30\n",
      "2006/2006 [==============================] - 7s 4ms/sample - loss: 0.5462\n",
      "Epoch 13/30\n",
      "2006/2006 [==============================] - 8s 4ms/sample - loss: 0.4406\n",
      "Epoch 14/30\n",
      "2006/2006 [==============================] - 6s 3ms/sample - loss: 0.3656\n",
      "Epoch 15/30\n",
      "2006/2006 [==============================] - 5s 3ms/sample - loss: 0.3280\n",
      "Epoch 16/30\n",
      "2006/2006 [==============================] - 5s 2ms/sample - loss: 0.2693\n",
      "Epoch 17/30\n",
      "2006/2006 [==============================] - 5s 3ms/sample - loss: 0.2277\n",
      "Epoch 18/30\n",
      "2006/2006 [==============================] - 6s 3ms/sample - loss: 0.1953\n",
      "Epoch 19/30\n",
      "2006/2006 [==============================] - 6s 3ms/sample - loss: 0.1635\n",
      "Epoch 20/30\n",
      "2006/2006 [==============================] - 5s 3ms/sample - loss: 0.1464\n",
      "Epoch 21/30\n",
      "2006/2006 [==============================] - 5s 2ms/sample - loss: 0.1322\n",
      "Epoch 22/30\n",
      "2006/2006 [==============================] - 4s 2ms/sample - loss: 0.1305\n",
      "Epoch 23/30\n",
      "2006/2006 [==============================] - 5s 3ms/sample - loss: 0.1115\n",
      "Epoch 24/30\n",
      "2006/2006 [==============================] - 6s 3ms/sample - loss: 0.1041\n",
      "Epoch 25/30\n",
      "2006/2006 [==============================] - 5s 2ms/sample - loss: 0.0994\n",
      "Epoch 26/30\n",
      "2006/2006 [==============================] - 4s 2ms/sample - loss: 0.1028\n",
      "Epoch 27/30\n",
      "2006/2006 [==============================] - 5s 2ms/sample - loss: 0.0965\n",
      "Epoch 28/30\n",
      "2006/2006 [==============================] - 5s 3ms/sample - loss: 0.1135\n",
      "Epoch 29/30\n",
      "2006/2006 [==============================] - 5s 2ms/sample - loss: 0.0879\n",
      "Epoch 30/30\n",
      "2006/2006 [==============================] - 4s 2ms/sample - loss: 0.0814\n",
      "finished Round 0\n"
     ]
    }
   ],
   "source": [
    "### train the LSTM Classifier\n",
    "\n",
    "\n",
    "# the inputting dataframes\n",
    "df_train_semEval.index = range(len(df_train_semEval))\n",
    "df_test_semEval.index = range(len(df_train_semEval),len(df_train_semEval)+len(df_test_semEval))\n",
    "Y_train_semEval = df_train_semEval['Label'].tolist()\n",
    "Y_test_semEval = df_test_semEval['Label'].tolist()\n",
    "\n",
    "\n",
    "# prepare the dataframes for LSTM\n",
    "df_train_semEval2 = addInxcolDf(df_train_semEval)\n",
    "df_train_semEval3 = add3colDf(df_train_semEval2)\n",
    "df_test_semEval2 = addInxcolDf(df_test_semEval)\n",
    "df_test_semEval3 = add3colDf(df_test_semEval2)\n",
    "\n",
    "Y_binary = np.array(list(zip([1 if i ==0 else 0 for i in Y_train_semEval], Y_train_semEval)))\n",
    "\n",
    "\n",
    "\n",
    "for rd in range(1):\n",
    "\n",
    "    NameTag = 'LSTM_Round{}'.format(rd)\n",
    "\n",
    "\n",
    "    ### train the LogisticRegression classifer and evaluate\n",
    "    X_train = get_feature_arrays(df_train_semEval3)\n",
    "    model = get_model()\n",
    "    batch_size = 64\n",
    "    model.fit(X_train, Y_binary, batch_size=batch_size, epochs=get_n_epochs())\n",
    "\n",
    "    ### evaluate this classifer\n",
    "    X_test = get_feature_arrays(df_test_semEval3)\n",
    "    probs_test = model.predict(X_test)\n",
    "    preds_test = np.array([1 if r[1] > r[0] else 0 for r in probs_test])\n",
    "\n",
    "    df_res_dev = df_res_dev.append({'tag': NameTag,\n",
    "                                    # TODO: add one column : all samples; predicted postive , real postive, overlap postive\n",
    "                                    'Nb:allsamp,predpos,realpos,overlap': [len(preds_test), Counter(preds_test)[1], Counter(Y_test_semEval)[1], \n",
    "                                    len([i for inx, i in enumerate(preds_test) if i == Y_test_semEval[inx]])],\n",
    "                                    # metrics values\n",
    "                                    'accuracy': metrics.accuracy_score(Y_test_semEval, preds_test), \n",
    "                                    'precision': metrics.precision_score(Y_test_semEval, preds_test),\n",
    "                                    'recall': metrics.recall_score(Y_test_semEval, preds_test),\n",
    "                                    'F1': metrics.f1_score(Y_test_semEval, preds_test),\n",
    "                                   }, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    print(\"finished Round {}\".format(rd))\n",
    "\n",
    "# save results to disk\n",
    "# df_res_dev.to_pickle(path_here+ \"/res/df_res_dev.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2cd38b25-935f-40ef-90e7-13c84ae76d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# purpose: find only the positive sentences, tag the forward as 1 and backward as 0\n",
    "# input: the dataframe ready for train \n",
    "# output: the dataframe with all positive examples, but tag the forward as 1 and backward as 0\n",
    "def TagCausalDirec(df):\n",
    "     \n",
    "    # only extract the positive examples\n",
    "    df_dir = df[df['Label']==1]\n",
    "\n",
    "    for inx, rows in df_dir.iterrows():\n",
    "        c_single = re.split(' |-', rows['Cause'])[0]\n",
    "        e_single = re.split(' |-', rows['Effect'])[0]\n",
    "        if rows['tokens'].index(c_single) > rows['tokens'].index(e_single):\n",
    "            df_dir.loc[inx, 'Label'] = 0\n",
    "        \n",
    "    return df_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee9857b6-61b0-4b21-90ce-f7549abbbac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/snorkel/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "df_train_semEval4 = TagCausalDirec(df_train_semEval3)\n",
    "# only use the test that are tagged as positive by the last LSTM\n",
    "df_test_semEval4 = TagCausalDirec(df_test_semEval3[[True if i == 1 else False for i in preds_test]])\n",
    "\n",
    "# get the real labels for those dataframe\n",
    "Y_train_semEval = np.array(df_train_semEval4['Label'].to_list())\n",
    "Y_binary = np.array(list(zip([1 if i ==0 else 0 for i in Y_train_semEval], Y_train_semEval)))\n",
    "Y_test_semEval = np.array(df_test_semEval4['Label'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "97505597-18bd-4663-9665-3abc713d57c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1003/1003 [==============================] - 7s 7ms/sample - loss: 0.6532\n",
      "Epoch 2/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.6467\n",
      "Epoch 3/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.6390\n",
      "Epoch 4/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.6320\n",
      "Epoch 5/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.6181\n",
      "Epoch 6/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.5845\n",
      "Epoch 7/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.5261\n",
      "Epoch 8/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.4042\n",
      "Epoch 9/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.2340\n",
      "Epoch 10/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.1808\n",
      "Epoch 11/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.1634\n",
      "Epoch 12/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.1403\n",
      "Epoch 13/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.1343\n",
      "Epoch 14/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.1069\n",
      "Epoch 15/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.1094\n",
      "Epoch 16/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.0913\n",
      "Epoch 17/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.0746\n",
      "Epoch 18/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.0734\n",
      "Epoch 19/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.0658\n",
      "Epoch 20/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.0775\n",
      "Epoch 21/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.0599\n",
      "Epoch 22/30\n",
      "1003/1003 [==============================] - 3s 3ms/sample - loss: 0.0583\n",
      "Epoch 23/30\n",
      "1003/1003 [==============================] - 3s 3ms/sample - loss: 0.0585\n",
      "Epoch 24/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.0481\n",
      "Epoch 25/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.0418\n",
      "Epoch 26/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.0399\n",
      "Epoch 27/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.0349\n",
      "Epoch 28/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.0323\n",
      "Epoch 29/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.0298\n",
      "Epoch 30/30\n",
      "1003/1003 [==============================] - 2s 2ms/sample - loss: 0.0309\n",
      "finished Round 0\n"
     ]
    }
   ],
   "source": [
    "### train the LSTM the 2nd time to predict the direction of causal pairs\n",
    "\n",
    "NameTag = 'LSTM_Direction'\n",
    "\n",
    "\n",
    "### train the LogisticRegression classifer and evaluate\n",
    "X_train = get_feature_arrays(df_train_semEval4)\n",
    "model = get_model()\n",
    "batch_size = 64\n",
    "model.fit(X_train, Y_binary, batch_size=batch_size, epochs=get_n_epochs())\n",
    "\n",
    "### evaluate this classifer\n",
    "X_test = get_feature_arrays(df_test_semEval4)\n",
    "probs_test = model.predict(X_test)\n",
    "preds_test = np.array([1 if r[1] > r[0] else 0 for r in probs_test])\n",
    "\n",
    "df_res_dev = df_res_dev.append({'tag': NameTag,\n",
    "                                # TODO: add one column : all samples; predicted postive , real postive, overlap postive\n",
    "                                'Nb:allsamp,predpos,realpos,overlap': [len(preds_test), Counter(preds_test)[1], Counter(Y_test_semEval)[1], \n",
    "                                len([i for inx, i in enumerate(preds_test) if i == Y_test_semEval[inx]])],\n",
    "                                # metrics values\n",
    "                                'accuracy': metrics.accuracy_score(Y_test_semEval, preds_test), \n",
    "                                'precision': metrics.precision_score(Y_test_semEval, preds_test),\n",
    "                                'recall': metrics.recall_score(Y_test_semEval, preds_test),\n",
    "                                'F1': metrics.f1_score(Y_test_semEval, preds_test),\n",
    "                               }, ignore_index=True)\n",
    "\n",
    "\n",
    "print(\"finished Round {}\".format(rd))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "966a19b5-34b4-405e-8cf9-e5708adf1243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "ground truth:  germs  -->  cold\n",
      "predict:  cold  -->  germs\n",
      "From banishing cold and flu germs to preventing foodborne illnesses, frequent hand-washing is one of the smartest preventive habits you can adopt.\n",
      "----------------------\n",
      "ground truth:  injury  -->  dizziness\n",
      "predict:  dizziness  -->  injury\n",
      "Headaches, dizziness, balance problems, and neck and back pain were caused by the work injury.\n",
      "----------------------\n",
      "ground truth:  liquids  -->  burns\n",
      "predict:  burns  -->  liquids\n",
      "Heat burns, or thermal burns, are caused by steam, fire, hot objects or hot liquids.\n",
      "----------------------\n",
      "ground truth:  cyclone  -->  flooding\n",
      "predict:  flooding  -->  cyclone\n",
      "The flooding, caused by a cyclone, came on the heels of a prolonged drought, which destroyed 60 percent of Fiji's sugar cane crop last year and cost more than 50 million Fijian dollars (25 million US) in relief and rehabilitation.\n",
      "----------------------\n",
      "ground truth:  joystick  -->  force\n",
      "predict:  force  -->  joystick\n",
      "When the force was generated via the joystick, the reproduced force matched the original force much more accurately.\n",
      "----------------------\n",
      "ground truth:  virus  -->  influenza\n",
      "predict:  influenza  -->  virus\n",
      "During the first documented outbreak of human infections with H5N1, which occurred in Hong Kong in 1997, the 18 human cases coincided with an outbreak of highly pathogenic avian influenza, caused by a virtually identical virus, in poultry farms and live markets.\n"
     ]
    }
   ],
   "source": [
    "### results presentations\n",
    "\n",
    "### the false sentences that are predcited as postive \n",
    "for inx, rows in df_test_semEval4.reset_index().iterrows():\n",
    "    if rows['Label'] == 0 and preds_test[inx] == 1:\n",
    "        print(\"----------------------\")\n",
    "        print(\"ground truth: \", rows['Cause'], \" --> \", rows['Effect'])\n",
    "        print(\"predict: \", rows['Effect'], \" --> \", rows['Cause'])\n",
    "        print(rows['Sent'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cfb508-6430-45c7-a41b-53173a2d8977",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
